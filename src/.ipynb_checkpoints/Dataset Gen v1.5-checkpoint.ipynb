{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import seaborn \n",
    "import peakutils\n",
    "import wfdb\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/Users/oobiri/Documents/Carleton/AFDetect/data/ltaf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets patient Ids - Patients 00735 & 03665 raw data is unavailabe, patients 04936 & 05091 include incorrect annotation\n",
    "def get_ids(filePath):\n",
    "    patientIds = []\n",
    "    \n",
    "    for filename in listdir(dataPath):\n",
    "        if filename.endswith(\".dat\") and '04936' not in filename and '05091' not in filename:\n",
    "            newName = filename.replace('.dat','')\n",
    "            patientIds.append(newName)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return patientIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pIds = get_ids(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for pi in pIds:\n",
    "    file = dataPath + pi\n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    sym = annotation.symbol\n",
    "    \n",
    "    values, counts = np.unique(sym, return_counts=True)\n",
    "    df_sub = pd.DataFrame({'sym':values, 'val':counts, 'pi':[pi]*len(counts)})\n",
    "    df = pd.concat([df, df_sub], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sym\n",
       "N    8710873\n",
       "A     152332\n",
       "V     132679\n",
       "+      53704\n",
       "\"       5959\n",
       "Q         89\n",
       "Name: val, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sym').val.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonBeat = [\"[\", \"!\", \"]\", \"x\", \"(\", \")\", \"p\", \"t\", \"u\", \"`\", \"'\", \"^\", \"|\", \"~\", \"+\", \"s\", \"T\", \"*\", \"D\", \"=\", '\"', \"@\"]\n",
    "\n",
    "#For when using arrythmia datasets\n",
    "abnormalBeat =  [\"L\", \"R\", \"B\", \"A\", \"a\", \"J\", \"S\", \"V\", \"r\", \"F\", \"e\", \"j\", \"n\", \"E\", \"/\", \"f\", \"Q\", \"?\"]\n",
    "\n",
    "afBeat = \"A\"\n",
    "\n",
    "nonafBeat = [\"L\", \"R\", \"B\", \"N\", \"a\", \"J\", \"S\", \"V\", \"r\", \"F\", \"e\", \"j\", \"n\", \"E\", \"/\", \"f\", \"Q\", \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that loads a patient's signls and annotations\n",
    "def load_ecg(file):\n",
    "    record = wfdb.rdrecord(file)\n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    \n",
    "    p_signal = record.p_signal\n",
    "    \n",
    "    ann_sym = annotation.symbol\n",
    "    ann_sample = annotation.sample\n",
    "    \n",
    "    return p_signal, ann_sym, ann_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the x,y matrices for each beat\n",
    "def build_XY(p_signal, df_ann, num_cols, nonaf):\n",
    "    numRows = len(df_ann)\n",
    "    \n",
    "    #initialize arrays\n",
    "    signals = np.zeros((numRows, num_cols))\n",
    "    labels = np.zeros((numRows, 1))\n",
    "    sym = []\n",
    "    \n",
    "    max_row = 0 \n",
    "    \n",
    "    for ann_sample, ann_sym in zip(df_ann.ann_sample.values, df_ann.ann_sym.values):\n",
    "        left = max([0, ann_sample - num_sec*fs])\n",
    "        right = min([len(p_signal), (ann_sample + num_sec*fs)])\n",
    "        x = p_signal[left: right]\n",
    "        if len(x) == num_cols:\n",
    "            signals[max_row,:] = x\n",
    "            labels[max_row,:] = int(ann_sym in nonaf) #\n",
    "            sym.append(ann_sym)\n",
    "            max_row += 1\n",
    "            \n",
    "    signals = signals[:max_row,:]\n",
    "    labels = labels[:max_row,:]\n",
    "    \n",
    "    return signals, labels, sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dataset that is centered on beats +- 15 seconds before and after\n",
    "def create_dataset(pids, num_sec, fs, nonaf):\n",
    "    \n",
    "    num_cols = 2*num_sec*fs\n",
    "    all_signals = np.zeros((1,num_cols))\n",
    "    all_labels = np.zeros((1,1))\n",
    "    all_sym = []\n",
    "    \n",
    "    max_rows = []\n",
    "    \n",
    "    for pi in pids:\n",
    "        file = dataPath + pi\n",
    "        \n",
    "        p_signal, ann_sym, ann_sample = load_ecg(file)\n",
    "        \n",
    "        # grab the first signal\n",
    "        p_signal = p_signal[:,0]\n",
    "        \n",
    "        # make df to exclude the nonbeats\n",
    "        df_ann = pd.DataFrame({'ann_sym':ann_sym,\n",
    "                              'ann_sample':ann_sample})\n",
    "        df_ann = df_ann.loc[df_ann.ann_sym.isin(nonaf + ['A'])]\n",
    "        \n",
    "        X,Y,sym = build_XY(p_signal,df_ann, num_cols, nonaf)\n",
    "        all_sym = all_sym+sym\n",
    "        max_rows.append(X.shape[0])\n",
    "        all_signals = np.append(all_signals,X,axis = 0)\n",
    "        all_labels = np.append(all_labels,Y,axis = 0)\n",
    "    # drop the first zero row\n",
    "    all_signals = all_signals[1:,:]\n",
    "    all_labels = all_labels[1:,:]\n",
    "    \n",
    "    # check sizes make sense\n",
    "    assert np.sum(max_rows) == all_signals.shape[0], 'number of signals, max_rows rows messed up'\n",
    "    assert all_labels.shape[0] == all_signals.shape[0], 'number of signals, labels rows messed up'\n",
    "    assert all_labels.shape[0] == len(all_sym), 'number of labels, sym rows messed up'\n",
    "\n",
    "    return all_signals, all_labels, all_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sec = 15\n",
    "fs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals, all_labels, all_sym = create_dataset(pIds, num_sec, fs, nonafBeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(all_signals, all_labels, test_size=0.33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
